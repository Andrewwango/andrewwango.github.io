---
layout: post
title: "Topics and materials for 4F10"
other: y
date: 2000-01-01 00:00:00 +0000
description:  # Add post description (optional)
img: # Add image post (optional)
tags: [cambridge] # add tag
---

A collection of topics and materials for 4F10: Deep Learning and Structured Data in 2022.

Key of what's expected (hopefully...):
- 游댮 important topic, mathematical detail
- 游리 understanding of concepts
- 游릭 awareness

- **Lecture 1: "Introduction"**
    - Nothing of use presented in this lecture
- **Lecture 2: "Probability of Error & Decision Boundaries"**
    - 游댮 Much better explained in this very clear tutorial on Linear and Quadratic Disciminant Analysis: [arXiv](https://arxiv.org/abs/1906.02590)
    - 游댮 Bayes decision rule: slides 4-6
- **Lecture 3: "Graphical Models and Conditional Independence"**, and Undirected GMs (Markov Networks)
    - 游댮 CIs: slides 4-6
    - 游리 Markov networks: [Murphy ch19](https://www.cs.ubc.ca/~murphyk/MLbook/pml-print3-ch19.pdf), section 19.3.1.
- **Lecture 4,5,6: "Latent Variable and Sequence Models"**
    - 游리 Factor Analysis [sklearn](https://scikit-learn.org/stable/modules/decomposition.html#factor-analysis)
    - 游댮 EM for learning GMM - [Murphy 11.4.2](https://andrewwango.github.io/assets/pdf/Murphy_PML_sec11_4.pdf)
    - HMMs:
        - 游댮 General: see [3F8 notes](https://andrewwango.github.io/assets/pdf/3F8_sequence_modelling.pdf)
        - 游리 Inference: Discrete Kalman Filter & Viterbi algorithm: [Murphy section 17.4](https://andrewwango.github.io/assets/pdf/Murphy_PML_sec17_4.pdf), see also 3F8
        - 游리 Learning: EM (not covered really)
    - 游릭 Conditional Random Fields - model description, motivation, and learning [Murphy section 19.6](https://andrewwango.github.io/assets/pdf/Murphy_PML_sec19_6.pdf)
- **Lecture 7,8: "Deep Learning"**
    - A very poor intro to DL where everything is just in the wrong order - see instead chapters in the tutorials on [d2l.ai](http://d2l.ai):
        - 游댮 Linear network intro: [d2l.ai](http://d2l.ai/chapter_linear-networks) 
        - 游댮 MLPs: [d2l.ai](http://d2l.ai/chapter_multilayer-perceptrons) 
            - Network configuration: [MLM](https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/)
        - 游댮 Network training: [d2l.ai](http://d2l.ai/chapter_multilayer-perceptrons/backprop.html ) 
            - Batch normalisation [d2l.ai](http://d2l.ai/chapter_convolutional-modern/batch-norm.html)
            - Regularisation: [TDS](https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036)
        - 游댮 CNNs: [d2l.ai](http://d2l.ai/chapter_convolutional-neural-networks) 
            - Pooling: [d2l.ai](http://d2l.ai/chapter_convolutional-neural-networks/pooling.html)
        - 游댮 ResNets: [d2l.ai](http://d2l.ai/chapter_convolutional-modern/resnet.html ) 
            - Highway layers: [PWC](https://paperswithcode.com/method/highway-layer)
        - 游리 Advanced optimisation algorithms: [d2l.ai](http://d2l.ai/chapter_optimization) 
    - 游댮 Initialisation and Xavier initialisation: [deeplearning.ai](https://www.deeplearning.ai/ai-notes/initialization/)
- **Lecture 9,10: "Deep Learning for Sequence Data"**
    - 游댮 RNNs (slides 4-7, seq to target): [Blog](https://victorzhou.com/blog/intro-to-rnns/) and [d2l.ai](https://d2l.ai/chapter_recurrent-neural-networks/rnn.html)
    - 游릭 Elman vs Jordan networks: slide 8
    - 游릭 Bi-directional RNNs: [d2l.ai](https://d2l.ai/chapter_recurrent-modern/bi-rnn.html)
    - 游리 LSTMs and GRUs: [Blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
    - Seq2seq/encoder-decoder model with attention:
        - 游리 Overview with application to Neural Machine Translation: [Jalammar blog](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
        - 游리 Focus on seq2seq model: [d2l.ai](https://d2l.ai/chapter_recurrent-modern/seq2seq.html)
        - 游댮 Focus on attention types: [d2l.ai](https://d2l.ai/chapter_attention-mechanisms/attention-scoring-functions.html)
    - 游릭 Target to sequence: slides 37-40.
    - 游릭 Word2vec [Overview blog](https://wiki.pathmind.com/word2vec), [More thorough treatment](https://d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html?highlight=word2vec)
    - 游릭 Transformers: [Jalammar blog](https://jalammar.github.io/illustrated-transformer/)
    - 游릭 Introduction to BERT: [Jalammar blog](https://jalammar.github.io/illustrated-bert/)
- **Lecture 11: "Ensemble Methods"**
    - 游리 Dropout: [Medium](https://prvnk10.medium.com/ensemble-methods-and-the-dropout-technique-95f36e4ae9be)
    - 游리 Bagging: [TDS](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)
    - 游릭 Model compression: [Medium](https://medium.com/analytics-vidhya/knowledge-distillation-in-a-deep-neural-network-c9dd59aff89b)
- 游댮 **Lecture 12: "Support Vector Machines"** - ok, this is actually quite good
- 游댮 **Lecture 13: "Support Vector Machines: Advanced Topics"** (kernel SVM) - good too
- 游릭 **Lecture 14: "Kernels for Structured Data"** - good enough